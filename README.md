# ğŸ¨ Image Colorization with Conditional GANs

This project explores image-to-image translation using **Conditional Generative Adversarial Networks (cGANs)** to colorize grayscale images. The model is trained to generate colorized versions of black-and-white images, guided by paired training data.

## ğŸ§  What I Did

- Implemented a **cGAN architecture** using **PyTorch**
- Trained on paired grayscale/color image datasets
- Designed a **U-Net-based generator** and **PatchGAN discriminator**
- Benchmarked performance against a **pretrained ResNet18** baseline
- Achieved improved color fidelity and better structural consistency
- Visualized output vs ground truth side-by-side in the notebook

## ğŸ§ª Key Tools & Libraries

- Python
- PyTorch
- torchvision
- NumPy, Matplotlib

## ğŸ“ Files

- `FINAL_DNN.ipynb`: Full notebook including training loop, loss curves, visual outputs, and comparison with baseline model

## ğŸ–¼ï¸ Sample Output

> (ğŸ“¸ You can add a screenshot of generated vs. ground truth images here!)

## ğŸ” Why This Matters

Image colorization is a meaningful application of deep learning in areas like:
- Restoration of historical photographs
- Medical imaging
- Satellite data visualization

This project also serves as a hands-on example of working with **generative models**, adversarial training, and evaluating with pretrained classifiers.

## ğŸ“Œ Author

[Roya Joulaei Vijouyeh](https://github.com/RoyaJV97)

---

ğŸ‘©â€ğŸ”¬ *Interested in how this connects to Physics-Informed Machine Learning or scientific data? Reach out! I'm currently applying to PhD programs in AI and scientific ML.*

